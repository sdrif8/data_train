{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdrif8/data_train/blob/main/Train_YOLO_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sUfcA8ZgR2t"
      },
      "source": [
        "# Train YOLO Models in Google Colab\n",
        "**Author:** Evan Juras, [EJ Technology Consultants](https://ejtech.io)\n",
        "\n",
        "**Last updated:** January 3, 2025\n",
        "\n",
        "**GitHub:** [Train and Deploy YOLO Models](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models)\n",
        "\n",
        "# Introduction\n",
        "\n",
        "This notebook uses [Ultralytics](https://docs.ultralytics.com/) to train YOLO11, YOLOv8, or YOLOv5 object detection models with a custom dataset. At the end of this Colab, you'll have a custom YOLO model that you can run on your PC, phone, or edge device like the Raspberry Pi.\n",
        "\n",
        "<p align=center>\n",
        "<img src=\"https://s3.us-west-1.amazonaws.com/evanjuras.com/img/yolo-model-demo.gif\" height=\"360\"><br>\n",
        "<i>Custom YOLO candy detection model in action!</i>\n",
        "</p>\n",
        "\n",
        "I created a YouTube video that walks through this guide step by step. I recommend following along with the video while working through this notebook.\n",
        "\n",
        "<p align=center>\n",
        "<a href=\"https://youtu.be/r0RspiLG260\" target=\"_blank\"><img src=\"https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/doc/Train_YOLO_Thumbnail2.png\" height=\"240\"><br>\n",
        "<i>Click here to go to the video!</i></a>\n",
        "</p>\n",
        "\n",
        "**Important note: This notebook will be continuously updated to make sure it works with newer versions of Ultralytics and YOLO. If you see any differences between the YouTube video and this notebook, always follow the notebook!**\n",
        "\n",
        "### Working in Colab\n",
        "Colab provides a virtual machine in your browser complete with a Linux OS, filesystem, Python environment, and best of all, a free GPU. We'll install PyTorch and Ultralytics in this environment and use it to train our model. Simply click the Play button on sections of code in this notebook to execute them on the virtual machine.\n",
        "\n",
        "### Navigation\n",
        "To navigate this notebook, use the table of contents in the left sidebar to jump from section to section.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verify NVIDIA GPU Availability**\n",
        "\n",
        "Make sure you're using a GPU-equipped machine by going to \"Runtime\" -> \"Change runtime type\" in the top menu bar, and then selecting one of the GPU options in the Hardware accelerator section. Click Play on the following code block to verify that the NVIDIA GPU is present and ready for training."
      ],
      "metadata": {
        "id": "3NW7LLv_QPOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "cfaWho47RGDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2cdf356-8c6a-490d-b171-eb08642a1db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb 10 16:12:09 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIHu25pnjjJ1"
      },
      "source": [
        "#1.&nbsp;Gather and Label Training Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6Y1vBiRjpcq"
      },
      "source": [
        "Before we start training, we need to gather and label images that will be used for training the object detection model. A good starting point for a proof-of-concept model is 200 images. The training images should have random objects in the image along with the desired objects, and should have a variety of backgrounds and lighting conditions.\n",
        "\n",
        "There are a couple options for gathering images:\n",
        "\n",
        "\n",
        "*   Build a custom dataset by taking your own pictures of the objects and labeling them (this typically results in the best performance)\n",
        "*   Find a pre-made dataset from sources like [Roboflow Universe](), [Kaggle](), or [Google Images V7]()\n",
        "\n",
        "\n",
        "If you want to build your own dataset, there are several tools available for labeling images. One good option is [Label Studio](https://labelstud.io/?utm_source=youtube&utm_medium=video&utm_campaign=edjeelectronics), a free and open-source labeling tool that has a simple workflow while providing capabilities for more advanced features. My YouTube video that walks through this notebook (link to be added soon) shows how to label images with Label Studio.\n",
        "\n",
        "<p align=center>\n",
        "<img src=\"https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/doc/label-studio-example.PNG\" height=\"380\"><br>\n",
        "<i>Example of a candy image labeled with Label Studio.</i>\n",
        "</p>\n",
        "\n",
        "If you used Label Studio to label and export the images, they'll be exported in a `project.zip` file that contains the following:\n",
        "\n",
        "- An `images` folder containing the images\n",
        "- A `labels` folder containing the labels in YOLO annotation format\n",
        "- A `classes.txt` labelmap file that contains all the classes\n",
        "- A `notes.json` file that contains info specific to Label Studio (this file can be ignored)\n",
        "\n",
        "If you obtained your dataset from another source (like Roboflow Universe) or used another tool to label your dataset, make sure the files are organized in the same folder structure.\n",
        "\n",
        "<p align=center>\n",
        "<img src=\"https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/doc/zipped-data-example.png\" height=\"\"><br>\n",
        "<i>Organize your data in the folders shown here. See my <a href=\"https://s3.us-west-1.amazonaws.com/evanjuras.com/resources/candy_data_06JAN25.zip\">Candy Detection Dataset</a> for an example.</i>\n",
        "</p>\n",
        "\n",
        "Once you've got your dataset built, put into the file structure shown above, and zipped into `data.zip`, you're ready to move on to the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eDhuvzDfIFS"
      },
      "source": [
        "# 2.&nbsp;Upload Image Dataset and Prepare Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW_0c110fOiz"
      },
      "source": [
        "Next, we'll upload our dataset and prepare it for training with YOLO. We'll split the dataset into train and validation folders, and we'll automatically generate the configuration file for training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Upload images\n",
        "\n",
        "First, we need to upload the dataset to Colab. Here are a few options for moving the `data.zip` folder into this Colab instance."
      ],
      "metadata": {
        "id": "FwKAqFIQSBpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Option 1. Upload through Google Colab**\n",
        "\n",
        "Upload the `data.zip` file to the Google Colab instance by clicking the \"Files\" icon on the left hand side of the browser, and then the \"Upload to session storage\" icon. Select the zip folder to upload it.\n",
        "\n",
        "<p>\n",
        "<br>\n",
        "<img src=\"https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/doc/upload-colab-files.png\" height=\"240\">\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "ZPZEM27IOh79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Option 2. Copy from Google Drive**\n",
        "\n",
        "You can also upload your images to your personal Google Drive, mount the drive on this Colab session, and copy them over to the Colab filesystem. This option works well if you want to upload the images beforehand so you don't have to wait for them to upload each time you restart this Colab. If you have more than 50MB worth of images, I recommend using this option.\n",
        "\n",
        "First, upload the `data.zip` file to your Google Drive, and make note of the folder you uploaded them to. Replace `MyDrive/path/to/data.zip` with the path to your zip file. (For example, I uploaded the zip file to folder called \"candy-dataset1\", so I would use `MyDrive/candy-dataset1/data.zip` for the path). Then, run the following block of code to mount your Google Drive to this Colab session and copy the folder to this filesystem."
      ],
      "metadata": {
        "id": "TC4bZM1UWRdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp /content/gdrive/MyDrive/path/to/data.zip /content"
      ],
      "metadata": {
        "id": "ZfQBSwDdWoWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Option 3. Use my candy detection or coin detection dataset**\n",
        "\n",
        "If you just want to test the process on a pre-made dataset, you can use one of my datasets:\n",
        "\n",
        "*   [Candy image dataset](https://s3.us-west-1.amazonaws.com/evanjuras.com/resources/candy_data_14DEC24.zip), which contains 162 pictures of popular candies (Skittles, Snickers, etc)\n",
        "*   [Coin image dataset](https://s3.us-west-1.amazonaws.com/evanjuras.com/resources/YOLO_coin_data_12DEC30.zip), which contains 750 pictures of US coins (pennies, dimes, nickels, and quarters)\n",
        "\n",
        "Download one of the datasets by running the following code block. I'll use the candy detection dataset as the example for the rest of the notebook."
      ],
      "metadata": {
        "id": "q43_b9-sWsdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/sample_data/"
      ],
      "metadata": {
        "id": "M5ioHC5rWT3e"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "if os.path.isdir('/content/data'):\n",
        "    shutil.rmtree('/content/data')\n",
        "print('Ancien /content/data supprim√©.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHb9jIP824GB",
        "outputId": "a36bd468-c891-422d-eac1-3248565705c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ancien /content/data supprim√©.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Stopper les √©ventuels verrous/handles (facultatif)\n",
        "import gc, torch, os, shutil, glob\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# 2) Supprimer dossiers de donn√©es, runs, caches Ultralytics/PyTorch\n",
        "paths = [\n",
        "    \"/content/ds\",                # ton dataset pr√©par√©\n",
        "    \"/content/data\",              # split train/val/test\n",
        "    \"/content/runs\",              # sorties Ultralytics\n",
        "    \"/root/.config/Ultralytics\",  # config/caches Ultralytics\n",
        "]\n",
        "for p in paths:\n",
        "    if os.path.exists(p):\n",
        "        shutil.rmtree(p, ignore_errors=True)\n",
        "\n",
        "# 3) Supprimer checkpoints √©ventuels au niveau racine\n",
        "for p in glob.glob(\"/content/*.pt\"):\n",
        "    os.remove(p)\n",
        "\n",
        "print(\"Nettoyage termin√©.\")\n",
        "\n",
        "# 4) (Optionnel mais conseill√©) Red√©marrer le runtime manuellement via le menu Runtime > Restart session\n",
        "#    Si tu ne red√©marres pas, au moins relance l'installation des d√©pendances dans la cellule suivante."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QyoZRdZE0EJ",
        "outputId": "72e1a5bf-183c-41d9-e385-6e4e6b2f7278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nettoyage termin√©.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQXLBvL5grDl"
      },
      "outputs": [],
      "source": [
        "# To use my one of pre-made dataset instead of your own custom dataset, download it here (control which dataset is downloaded by commenting out either line)\n",
        "!wget -O /content/data.zip https://s3.us-west-1.amazonaws.com/evanjuras.com/resources/candy_data_06JAN25.zip # Candy dataset\n",
        "#!wget -O /content/data.zip https://s3.us-west-1.amazonaws.com/evanjuras.com/resources/YOLO_coin_data_12DEC30.zip # Coin dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Split images into train and validation folders"
      ],
      "metadata": {
        "id": "m7Iz9eBzW5zm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, whether you used Option 1, 2, or 3, you should be able to click the folder icon on the left and see your `data.zip` file in the list of files. Next, we'll unzip `data.zip` and create some folders to hold the images. Run the following code block to unzip the data."
      ],
      "metadata": {
        "id": "58JuFGc2PatU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z8O6z-wVcPEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414ea039-000f-4172-b686-dc7a60ce4fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ds pr√™t.\n"
          ]
        }
      ],
      "source": [
        "# 0) Extraire l‚Äôarchive (ajuste le chemin si besoin)\n",
        "!tar -xf /content/npu-bolt-DatasetNinja.tar -C /content/\n",
        "\n",
        "# 0bis) S‚Äôassurer qu‚Äôon a /content/ds avec 'img' et 'ann' (sinon renommer le dossier extrait)\n",
        "import os, shutil\n",
        "\n",
        "base = \"/content\"\n",
        "ds = os.path.join(base, \"ds\")\n",
        "\n",
        "if not os.path.isdir(ds):\n",
        "    candidates = [os.path.join(base, d) for d in os.listdir(base) if os.path.isdir(os.path.join(base, d))]\n",
        "    ok = [d for d in candidates if os.path.isdir(os.path.join(d, \"img\")) and os.path.isdir(os.path.join(d, \"ann\"))]\n",
        "    if ok:\n",
        "        print(\"Renommage:\", ok[0], \"->\", ds)\n",
        "        shutil.move(ok[0], ds)\n",
        "    else:\n",
        "        raise RuntimeError(\"Impossible de trouver un dossier contenant 'img' et 'ann'. V√©rifie l‚Äôarchive.\")\n",
        "else:\n",
        "    print(\"/content/ds pr√™t.\")\n",
        "\n",
        "# 0ter) Standardiser le dossier des images\n",
        "!mv /content/ds/img /content/ds/images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ultralytics requires a particular folder structure to store training data for models. Ultralytics requires a particular folder structure to store training data for models. The root folder is named ‚Äúdata‚Äù. Inside, there are two main folders:\n",
        "\n",
        "*   **Train**: These are the actual images used to train the model. In one epoch of training, every image in the train set is passed into the neural network. The training algorithm adjusts the network weights to fit the data in the images.\n",
        "\n",
        "\n",
        "*   **Validation**: These images are used to check the model's performance at the end of each training epoch.\n",
        "\n",
        "In each of these folders is a ‚Äúimages‚Äù folder and a ‚Äúlabels‚Äù folder, which hold the image files and annotation files respectively."
      ],
      "metadata": {
        "id": "eoPjqW6AYebn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I wrote a Python script that will automatically create the required folder structure and randomly move 90% of dataset to the \"train\" folder and 10% to the \"validation\" folder. Run the following code block to download and execute the scrpt."
      ],
      "metadata": {
        "id": "f2ohNAhWj41n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Convertir les JSON (ann) en .txt YOLO (labels)\n",
        "import os\n",
        "import json\n",
        "\n",
        "ann_folder = '/content/ds/ann'\n",
        "labels_folder = '/content/ds/labels'\n",
        "os.makedirs(labels_folder, exist_ok=True)\n",
        "\n",
        "# Classes EXACTEMENT comme dans 'classTitle' des JSON\n",
        "classes = [\"bolt side\", \"bolt nut\", \"bolt head\", \"blur bolt\"]\n",
        "\n",
        "def convert_json_to_yolo(json_path, txt_path):\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    img_w = data.get('size', {}).get('width')\n",
        "    img_h = data.get('size', {}).get('height')\n",
        "    if not img_w or not img_h:\n",
        "        with open(txt_path, 'w') as f:\n",
        "            f.write(\"\")\n",
        "        return\n",
        "\n",
        "    lines = []\n",
        "    for obj in data.get('objects', []):\n",
        "        if obj.get('geometryType') != 'rectangle':\n",
        "            continue\n",
        "        class_name = obj.get('classTitle', '')\n",
        "        if class_name not in classes:\n",
        "            continue\n",
        "        class_id = classes.index(class_name)\n",
        "\n",
        "        points = obj.get('points', {}).get('exterior', [])\n",
        "        if not isinstance(points, list) or len(points) < 2:\n",
        "            continue\n",
        "\n",
        "        x1, y1 = points[0]\n",
        "        x2, y2 = points[1]\n",
        "\n",
        "        x_center = ((x1 + x2) / 2) / img_w\n",
        "        y_center = ((y1 + y2) / 2) / img_h\n",
        "        width = abs(x2 - x1) / img_w\n",
        "        height = abs(y2 - y1) / img_h\n",
        "\n",
        "        lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
        "\n",
        "    with open(txt_path, 'w') as f:\n",
        "        f.write(\"\\n\".join(lines))\n",
        "\n",
        "# Conversion dossier ann -> labels\n",
        "for filename in os.listdir(ann_folder):\n",
        "    if filename.endswith('.json'):\n",
        "        json_file = os.path.join(ann_folder, filename)\n",
        "        txt_file = os.path.join(labels_folder, filename.replace('.json', '.txt'))\n",
        "        convert_json_to_yolo(json_file, txt_file)\n",
        "\n",
        "print(\"√âchantillon de labels convertis:\")\n",
        "print(\"\\n\".join(sorted(os.listdir(labels_folder))[:10]))"
      ],
      "metadata": {
        "id": "8X62eFTugosf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3a9ac1-ddeb-4a5c-be4a-05ade386f239"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "√âchantillon de labels convertis:\n",
            "AUT-0001.jpg.txt\n",
            "AUT-0002.jpg.txt\n",
            "AUT-0003.jpg.txt\n",
            "AUT-0004.jpg.txt\n",
            "AUT-0005.jpg.txt\n",
            "AUT-0006.jpg.txt\n",
            "AUT-0007.jpg.txt\n",
            "AUT-0008.jpg.txt\n",
            "AUT-0009.jpg.txt\n",
            "AUT-0010.jpg.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "labels_folder = '/content/ds/labels'\n",
        "img_exts = ('jpg', 'jpeg', 'png', 'JPG', 'JPEG', 'PNG')\n",
        "pattern = re.compile(rf'^(?P<base>.+)\\.(?P<ext>{\"|\".join(img_exts)})\\.txt$')\n",
        "\n",
        "# Passe 1: renommer *.jpg.txt -> *.txt\n",
        "for f in os.listdir(labels_folder):\n",
        "    if not f.lower().endswith('.txt'):\n",
        "        continue\n",
        "    src = os.path.join(labels_folder, f)\n",
        "    m = pattern.match(f)\n",
        "    if m:\n",
        "        new_name = m.group('base') + '.txt'\n",
        "        dst = os.path.join(labels_folder, new_name)\n",
        "        if os.path.exists(dst):\n",
        "            # fusion: si l‚Äôun des deux est non vide, garder le non vide\n",
        "            if os.path.getsize(dst) == 0 and os.path.getsize(src) > 0:\n",
        "                shutil.copy2(src, dst)\n",
        "            # sinon, garder dst tel quel (d√©j√† non vide ou les deux vides)\n",
        "            os.remove(src)\n",
        "        else:\n",
        "            shutil.move(src, dst)\n",
        "\n",
        "# V√©rification\n",
        "non_empty = sum(os.path.getsize(os.path.join(labels_folder, f))>0\n",
        "                for f in os.listdir(labels_folder) if f.endswith('.txt'))\n",
        "total = sum(1 for f in os.listdir(labels_folder) if f.endswith('.txt'))\n",
        "print(f\"Labels apr√®s normalisation -> non vides: {non_empty}, total: {total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hv-is32nT7i9",
        "outputId": "517c81cb-d781-4071-a8d7-c07b1ebac86c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels apr√®s normalisation -> non vides: 337, total: 337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "labels_folder = '/content/ds/labels'\n",
        "non_empty = 0\n",
        "empty = 0\n",
        "for f in os.listdir(labels_folder):\n",
        "    if f.endswith('.txt'):\n",
        "        p = os.path.join(labels_folder, f)\n",
        "        if os.path.getsize(p) > 0:\n",
        "            non_empty += 1\n",
        "        else:\n",
        "            empty += 1\n",
        "\n",
        "print(f\"Avant split -> non vides: {non_empty}, vides: {empty}, total: {non_empty+empty}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oteQafD1-_7",
        "outputId": "1da7092a-1673-4b97-db1e-8eba3462c951"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avant split -> non vides: 337, vides: 0, total: 337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split 81/9/10 avec garantie de labels non vides en val et test\n",
        "import os, random, shutil\n",
        "\n",
        "random.seed(42)\n",
        "images_dir = '/content/ds/images'\n",
        "labels_dir = '/content/ds/labels'\n",
        "out_base = '/content/data'\n",
        "\n",
        "# Reset dossiers\n",
        "for sub in ['train/images','train/labels','val/images','val/labels','test/images','test/labels']:\n",
        "    p = os.path.join(out_base, sub)\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "    for f in os.listdir(p):\n",
        "        os.remove(os.path.join(p, f))\n",
        "\n",
        "valid_exts = ('.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG')\n",
        "imgs = [f for f in os.listdir(images_dir) if f.endswith(valid_exts)]\n",
        "\n",
        "# S√©parer images avec objets vs sans objet\n",
        "with_obj, without_obj = [], []\n",
        "for img in imgs:\n",
        "    base = os.path.splitext(img)[0]\n",
        "    lblp = os.path.join(labels_dir, base + '.txt')\n",
        "    if os.path.exists(lblp) and os.path.getsize(lblp) > 0:\n",
        "        with_obj.append(img)\n",
        "    else:\n",
        "        without_obj.append(img)\n",
        "\n",
        "# Ratios papier: 81% train, 9% val, 10% test SUR images annot√©es\n",
        "random.shuffle(with_obj)\n",
        "n = len(with_obj)\n",
        "n_test = max(1, int(0.10 * n))\n",
        "n_val  = max(1, int(0.09 * n))\n",
        "test_imgs = set(with_obj[:n_test])\n",
        "val_imgs  = set(with_obj[n_test:n_test+n_val])\n",
        "train_imgs = set(with_obj[n_test+n_val:] + without_obj)\n",
        "\n",
        "def cp(img_name, dst_img_dir, dst_lbl_dir):\n",
        "    base = os.path.splitext(img_name)[0]\n",
        "    src_img = os.path.join(images_dir, img_name)\n",
        "    src_lbl = os.path.join(labels_dir, base + '.txt')\n",
        "    shutil.copy2(src_img, os.path.join(dst_img_dir, img_name))\n",
        "    if os.path.exists(src_lbl):\n",
        "        shutil.copy2(src_lbl, os.path.join(dst_lbl_dir, base + '.txt'))\n",
        "    else:\n",
        "        open(os.path.join(dst_lbl_dir, base + '.txt'), 'w').close()\n",
        "\n",
        "# Copier\n",
        "for im in train_imgs:\n",
        "    cp(im, os.path.join(out_base,'train','images'), os.path.join(out_base,'train','labels'))\n",
        "for im in val_imgs:\n",
        "    cp(im,   os.path.join(out_base,'val','images'),   os.path.join(out_base,'val','labels'))\n",
        "for im in test_imgs:\n",
        "    cp(im,  os.path.join(out_base,'test','images'),  os.path.join(out_base,'test','labels'))\n",
        "\n",
        "print(f\"Train images: {len(train_imgs)} | Val images: {len(val_imgs)} | Test images: {len(test_imgs)}\")\n",
        "\n",
        "# V√©rifications\n",
        "def count_non_empty(dir_):\n",
        "    return sum(os.path.getsize(os.path.join(dir_, f))>0 for f in os.listdir(dir_) if f.endswith('.txt'))\n",
        "\n",
        "print(\"Train labels non vides:\", count_non_empty(os.path.join(out_base,'train','labels')))\n",
        "print(\"Val labels non vides:\",   count_non_empty(os.path.join(out_base,'val','labels')))\n",
        "print(\"Test labels non vides:\",  count_non_empty(os.path.join(out_base,'test','labels')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0yppfvNjS_T",
        "outputId": "bfcc973d-04b6-4d36-d96d-5dc9c03b2160"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: 274 | Val images: 30 | Test images: 33\n",
            "Train labels non vides: 274\n",
            "Val labels non vides: 30\n",
            "Test labels non vides: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "\n",
        "def count_non_empty(dir_):\n",
        "    c_non_empty = 0\n",
        "    c_total = 0\n",
        "    for p in glob.glob(os.path.join(dir_, '*.txt')):\n",
        "        c_total += 1\n",
        "        if os.path.getsize(p) > 0:\n",
        "            c_non_empty += 1\n",
        "    return c_non_empty, c_total\n",
        "\n",
        "train_labels = '/content/data/train/labels'\n",
        "val_labels = '/content/data/validation/labels' if os.path.isdir('/content/data/validation/labels') else '/content/data/val/labels'\n",
        "\n",
        "tr_non_empty, tr_total = count_non_empty(train_labels)\n",
        "va_non_empty, va_total = count_non_empty(val_labels)\n",
        "print(f\"Train -> non vides: {tr_non_empty}/{tr_total}\")\n",
        "print(f\"Val   -> non vides: {va_non_empty}/{va_total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCuaf_gE2AJy",
        "outputId": "52d2d2e1-7539-4fda-fb0e-6da553d90c66"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train -> non vides: 274/274\n",
            "Val   -> non vides: 30/30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_yaml = \"\"\"path: /content/data\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "nc: 4\n",
        "names:\n",
        "  - bolt side\n",
        "  - bolt nut\n",
        "  - bolt head\n",
        "  - blur bolt\n",
        "\"\"\"\n",
        "with open(\"/content/data.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(data_yaml)\n",
        "\n",
        "# V√©rifier que le YAML est valide\n",
        "import yaml\n",
        "with open(\"/content/data.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "print(\"Charg√© OK:\", cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1iaq8O3jVlZ",
        "outputId": "22162dcd-fe5b-4653-c61c-37cdcbbf367a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charg√© OK: {'path': '/content/data', 'train': 'train/images', 'val': 'val/images', 'test': 'test/images', 'nc': 4, 'names': ['bolt side', 'bolt nut', 'bolt head', 'blur bolt']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.&nbsp;Install Requirements (Ultralytics)\n",
        "\n",
        "Next, we'll install the Ultralytics library in this Google Colab instance. This Python library will be used to train the YOLO model."
      ],
      "metadata": {
        "id": "B2L2qGCJzwY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Installer/mettre √† jour Ultralytics\n",
        "!pip install -q --upgrade ultralytics"
      ],
      "metadata": {
        "id": "EMEDk5byzxY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30f7efe-6171-4ed7-a7db-861167fbb928"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuZoMkSFN9XG"
      },
      "source": [
        "# 4.&nbsp;Configure Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's one last step before we can run training: we need to create the Ultralytics training configuration YAML file. This file specifies the location of your train and validation data, and it also defines the model's classes. An example configuration file model is available [here](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/datasets/coco128.yaml).\n",
        "\n",
        "Run the code block below to automatically generate a `data.yaml` configuration file. Make sure you have a labelmap file located at `custom_data/classes.txt`. If you used Label Studio or one of my pre-made datasets, it should already be present. If you assembled the dataset another way, you may have to manually create the `classes.txt` file (see [here](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/blob/main/doc/classes.txt) for an example of how it's formatted)."
      ],
      "metadata": {
        "id": "0c5Kdh0GmQHS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myP80_bnTNMi"
      },
      "source": [
        "# 5.&nbsp;Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Training Parameters\n",
        "Now that the data is organized and the config file is created, we're ready to start training! First, there are a few important parameters to decide on. Visit my article on [Training YOLO Models Locally](https://www.ejtech.io/learn/train-yolo-models) to learn more about these parameters and how to choose them.\n",
        "\n",
        "**Model architecture & size (`model`):**\n",
        "\n",
        "There are several YOLO11 models sizes available to train, including `yolo11n.pt`, `yolo11s.pt`, `yolo11m.pt`, `yolo11l.pt`, and `yolo11xl.pt`. Larger models run slower but have higher accuracy, while smaller models run faster but have lower accuracy. I made a brief YouTube video that compares performance of different YOLO models on a Raspberry Pi 5 and a laptop with a RTX 4050 GPU, [check it out here to get a sense of their speed accuracy](https://youtu.be/_WKS4E9SmkA). If you aren't sure which model size to use, `yolo11s.pt` is a good starting point.\n",
        "\n",
        "You can also train YOLOv8 or YOLOv5 models by substituting `yolo11` for `yolov8` or `yolov5`.\n",
        "\n",
        "\n",
        "**Number of epochs (`epochs`)**\n",
        "\n",
        "In machine learning, one ‚Äúepoch‚Äù is one single pass through the full training dataset. Setting the number of epochs dictates how long the model will train for. The best amount of epochs to use depends on the size of the dataset and the model architecture. If your dataset has less than 200 images, a good starting point is 60 epochs. If your dataset has more than 200 images, a good starting point is 40 epochs.\n",
        "\n",
        "\n",
        "**Resolution (`imgsz`)**\n",
        "\n",
        "Resolution has a large impact on the speed and accuracy of the model: a lower resolution model will have higher speed but less accuracy. YOLO models are typically trained and inferenced at a 640x640 resolution. However, if you want your model to run faster or know you will be working with low-resolution images, try using a lower resolution like 480x480.\n"
      ],
      "metadata": {
        "id": "DfKspYasCzC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Run Training!"
      ],
      "metadata": {
        "id": "V17UjYU5ZQdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code block to begin training. If you want to use a different model, number of epochs, or resolution, change `model`, `epochs`, or `imgsz`."
      ],
      "metadata": {
        "id": "nQi_hXnUVPr-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bbpob1gTPlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a52ab9-3df7-430f-ade8-22840658a149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.4.14 üöÄ Python-3.12.12 torch-2.9.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo26m.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 25.9MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
            "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
            "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5, 3, True]        \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
            " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1974784  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True, 0.5, True]\n",
            " 23        [16, 19, 22]  1   2804784  ultralytics.nn.modules.head.Detect           [4, 1, True, [256, 512, 512]] \n",
            "YOLO26m summary: 280 layers, 21,779,056 parameters, 21,779,056 gradients, 74.7 GFLOPs\n",
            "\n",
            "Transferred 756/768 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 92.0MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2180.7¬±1306.7 MB/s, size: 741.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/train/labels... 304 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 304/304 10.1it/s 30.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0002.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0003.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0004.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0005.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0006.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0007.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0008.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0009.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0010.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0011.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0012.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0013.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0015.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0016.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0018.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0019.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0020.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0021.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0022.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0023.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0025.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0027.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0028.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0029.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0030.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0031.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0032.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0033.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0034.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0035.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0037.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0038.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0039.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0040.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0041.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0042.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0043.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0044.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0045.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0046.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0047.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0048.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0049.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0050.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0051.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0052.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0053.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0054.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0055.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0056.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0057.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0059.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0061.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0062.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0063.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0064.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0065.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0066.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0067.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0068.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0069.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0070.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0071.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0072.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0073.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0074.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0075.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0076.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0077.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0078.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0079.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0080.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0081.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0082.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0084.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0085.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0086.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0087.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0088.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0089.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0090.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0091.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0092.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0093.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0094.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0095.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0096.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0097.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0098.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0099.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0108.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0109.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0110.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0111.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0112.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0113.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0114.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0115.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0116.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0118.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0119.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0122.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0123.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0124.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0125.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0126.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0127.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0128.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0129.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0130.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0131.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0132.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0133.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0134.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0135.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0136.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0140.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0143.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0144.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0146.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0147.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0149.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0151.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0152.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0153.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0154.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0155.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0157.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0158.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0159.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0160.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0161.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0162.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0163.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0164.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0165.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0166.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0167.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0168.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0169.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0170.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0171.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0172.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0173.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0174.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0175.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0176.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0177.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0178.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0179.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0180.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0181.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0182.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0183.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0185.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0186.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0187.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0188.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0189.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0190.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0191.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0192.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0193.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0194.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0195.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0197.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0198.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0199.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0200.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0202.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0203.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/data/train/images/AUT-0204.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1424.6¬±1306.1 MB/s, size: 1691.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/val/labels... 33 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 33/33 3.5it/s 9.5s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0001.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0014.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0017.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0024.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0026.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0036.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0058.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0060.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0083.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0117.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0120.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0121.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0145.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0148.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0150.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0156.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0184.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0196.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/data/val/images/AUT-0201.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/val/labels.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 124 weight(decay=0.0), 136 weight(decay=0.0005), 136 bias(decay=0.0)\n",
            "Plotting labels to /content/runs/detect/train2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      8.78G      1.318      4.968   0.004879        104        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.8s/it 35.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 5.2s/it 10.4s\n",
            "                   all         33        116      0.648      0.208      0.128     0.0697\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      9.01G      1.333      2.767   0.005203         99        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1it/s 17.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.2it/s 0.9s\n",
            "                   all         33        116      0.499      0.286      0.286      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      9.05G      1.399      1.973    0.00519        113        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.1it/s 0.9s\n",
            "                   all         33        116       0.82      0.253      0.316      0.203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      9.06G      1.376      1.544   0.005418        116        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.7it/s 1.2s\n",
            "                   all         33        116      0.773      0.308       0.34      0.209\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      9.08G      1.376      1.404   0.005125         85        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116       0.56      0.325      0.318      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      9.14G      1.343      1.383   0.004798         87        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.2it/s 0.9s\n",
            "                   all         33        116      0.293      0.397      0.312      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100      9.04G      1.376      1.295   0.004965        130        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.7it/s 1.2s\n",
            "                   all         33        116      0.685       0.44      0.447      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      9.08G      1.246      1.104   0.005048         75        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1it/s 17.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.291      0.443      0.399       0.25\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      9.03G      1.275      1.066   0.005079         96        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.2s/it 22.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.341      0.471      0.425      0.287\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      9.05G      1.297      1.031   0.004822         97        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.5it/s 0.8s\n",
            "                   all         33        116      0.452      0.432      0.505      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100      9.04G      1.287      1.002   0.004875        136        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.6it/s 0.8s\n",
            "                   all         33        116      0.631      0.428      0.442      0.298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100      9.04G      1.251     0.9332   0.004898         84        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.7it/s 1.2s\n",
            "                   all         33        116      0.441      0.452      0.472      0.296\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100      9.08G      1.269     0.9937   0.004973         92        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.793      0.345      0.463      0.323\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100      9.05G      1.191     0.9546   0.004658        141        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.513      0.502      0.523      0.355\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100      9.05G       1.22     0.8637   0.005045        111        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.556      0.407      0.503      0.347\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100      9.04G      1.158     0.7888   0.004592         69        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.496      0.527      0.518      0.338\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100      9.01G      1.158     0.7614    0.00429         79        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.729      0.575      0.582      0.393\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100      9.08G       1.13     0.8044   0.004118         88        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.8it/s 1.1s\n",
            "                   all         33        116      0.642      0.583      0.585       0.37\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100      9.08G      1.108     0.7612   0.004107        116        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.2it/s 0.9s\n",
            "                   all         33        116      0.926      0.363      0.528      0.347\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100      9.09G      1.118     0.7865   0.004029        107        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1it/s 16.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.2it/s 0.9s\n",
            "                   all         33        116      0.513      0.464      0.492      0.353\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100      8.99G      1.112     0.7515   0.004409        105        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.8it/s 1.1s\n",
            "                   all         33        116      0.478      0.412      0.507      0.361\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/100      9.08G      1.138     0.7426   0.004376        105        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.7it/s 0.7s\n",
            "                   all         33        116      0.551      0.487      0.543      0.364\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/100      9.07G      1.117     0.7203   0.004005         88        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.5it/s 0.8s\n",
            "                   all         33        116      0.525      0.448      0.518      0.364\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/100      9.04G      1.091     0.6387   0.004318         87        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.0it/s 1.0s\n",
            "                   all         33        116      0.783      0.447      0.484      0.343\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/100      9.09G      1.068     0.6283   0.003779        108        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.2it/s 0.9s\n",
            "                   all         33        116      0.426      0.509      0.468       0.32\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/100      9.08G      1.066     0.6671    0.00411        111        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.7it/s 0.8s\n",
            "                   all         33        116      0.818      0.458      0.548      0.363\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/100      9.04G       1.07     0.6765   0.004016         83        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.1it/s 0.9s\n",
            "                   all         33        116       0.42      0.545      0.524       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/100      9.09G       1.02     0.5606   0.003727        131        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.502      0.586      0.571      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/100      9.02G     0.9958     0.5787   0.003695         69        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.6it/s 0.8s\n",
            "                   all         33        116      0.436      0.568      0.541      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/100      9.05G      1.012     0.5214   0.003493         78        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.5it/s 1.3s\n",
            "                   all         33        116      0.478      0.516      0.576      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/100      9.07G      1.024     0.5939   0.003897         80        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.891      0.427      0.506       0.35\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/100      9.11G     0.9843     0.5498   0.003581        114        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.9it/s 0.7s\n",
            "                   all         33        116      0.556      0.519      0.563      0.389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/100      9.02G     0.9877     0.5479   0.003634        114        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.0it/s 1.0s\n",
            "                   all         33        116      0.836      0.511      0.538      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/100      9.08G      1.008     0.5634    0.00383        144        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.417      0.554      0.558      0.378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/100      9.12G     0.9666     0.5482   0.003715        158        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.434      0.422       0.45      0.313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/100      9.05G     0.9633     0.5361   0.003645         65        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.5it/s 0.8s\n",
            "                   all         33        116      0.561      0.428      0.522      0.373\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/100      9.02G     0.9765     0.5099   0.003265        126        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.536      0.532      0.581      0.389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/100      9.06G      0.957     0.5478   0.003358        101        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.8it/s 1.1s\n",
            "                   all         33        116      0.581      0.479      0.541      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/100      9.09G      0.951      0.504   0.003349         93        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.5it/s 0.8s\n",
            "                   all         33        116      0.561      0.561      0.558      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/100      9.09G     0.9361     0.5355    0.00324        133        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.433      0.519      0.563        0.4\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/100      8.99G     0.9556     0.5419   0.003347        103        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.8it/s 1.1s\n",
            "                   all         33        116        0.4      0.443      0.502      0.363\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/100      9.06G     0.9265     0.5258   0.003361         70        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.9s\n",
            "                   all         33        116      0.721      0.448      0.496      0.371\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/100      9.04G     0.9406     0.4945   0.003608         55        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116       0.67      0.484      0.475      0.348\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/100      9.05G     0.9165      0.481   0.003422         90        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.7it/s 1.2s\n",
            "                   all         33        116      0.438      0.494      0.511      0.371\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/100      9.01G     0.9012     0.4671   0.003361         70        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.405       0.51      0.511      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/100      9.04G     0.9133     0.4621    0.00307        139        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.2s/it 22.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.445      0.457      0.481      0.362\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/100      9.06G     0.8621     0.4508   0.003119         72        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.1it/s 0.9s\n",
            "                   all         33        116      0.743      0.429      0.517      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/100      9.05G     0.8972     0.4336   0.003123        109        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.6it/s 1.2s\n",
            "                   all         33        116      0.463      0.543      0.554      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/100      9.02G     0.8382     0.3978   0.003165         93        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.678      0.445      0.545      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/100      9.08G     0.8658     0.4388   0.003137         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.1it/s 0.9s\n",
            "                   all         33        116      0.426      0.514      0.558      0.393\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/100      9.17G     0.8658     0.4395   0.003243         86        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.8it/s 1.1s\n",
            "                   all         33        116      0.617      0.508      0.583      0.411\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/100       9.1G     0.8921     0.4281   0.003328        116        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.5it/s 0.8s\n",
            "                   all         33        116      0.631      0.508      0.557      0.392\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/100         9G     0.8638     0.4219   0.002889        110        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.726      0.459      0.535      0.383\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/100      9.09G     0.8328     0.4202   0.002796         93        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.7it/s 1.1s\n",
            "                   all         33        116      0.588      0.484       0.56      0.389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/100      9.09G     0.8482     0.3977    0.00297         71        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.515      0.457      0.488      0.355\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/100      9.04G     0.8235     0.3812   0.003036        103        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.1it/s 1.0s\n",
            "                   all         33        116      0.634      0.519       0.58      0.417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/100      8.99G      0.795     0.3654   0.002753         76        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.1it/s 1.0s\n",
            "                   all         33        116      0.599      0.513      0.595      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/100      9.07G     0.7654     0.3525    0.00296        108        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.855      0.477      0.572      0.407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/100      9.08G     0.8199     0.3899   0.002789        140        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.2it/s 0.9s\n",
            "                   all         33        116      0.418      0.502      0.573      0.408\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/100      9.07G     0.7831     0.3516   0.002698         91        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.2s/it 23.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.502      0.521       0.55      0.384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/100      8.99G     0.8204     0.3725    0.00279         83        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.9it/s 1.0s\n",
            "                   all         33        116      0.444      0.551      0.558      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/100      9.04G     0.7849     0.3542   0.002613         78        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1it/s 17.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.651       0.55      0.589      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/100      9.11G     0.7333     0.3446   0.002799        102        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.614      0.558      0.595      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/100      9.08G     0.7792     0.3392   0.002727        104        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.9it/s 1.1s\n",
            "                   all         33        116      0.781      0.531      0.612      0.417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/100      9.04G     0.7858     0.3326   0.002616         94        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.721      0.537      0.606      0.414\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/100      9.07G     0.7771     0.3438   0.002681         77        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.532      0.522      0.567      0.406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/100      9.04G     0.7486     0.3453   0.002704         98        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.5it/s 0.8s\n",
            "                   all         33        116       0.75      0.591      0.626      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/100      9.04G     0.7372     0.3165    0.00244        114        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.689      0.552      0.622      0.446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/100      9.03G      0.746     0.3153   0.002586        124        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.784      0.512      0.598      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/100       9.1G     0.7567     0.3444   0.002286        120        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.551      0.591      0.589      0.417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/100      9.09G     0.7233     0.3075   0.002345         80        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.9it/s 1.1s\n",
            "                   all         33        116      0.622      0.546      0.605      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/100      9.08G     0.7278     0.3048   0.002491         94        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.5it/s 0.8s\n",
            "                   all         33        116      0.745      0.595      0.627      0.438\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/100      9.12G     0.7116     0.3023   0.002405        112        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.737      0.564      0.632      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/100      9.07G      0.718     0.3108   0.002421         99        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.6it/s 1.2s\n",
            "                   all         33        116      0.575      0.553       0.62      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/100      9.08G      0.694     0.2894   0.002407        101        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1it/s 18.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.1it/s 1.0s\n",
            "                   all         33        116      0.628      0.591      0.637      0.441\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/100      9.04G     0.7212     0.3081    0.00247        120        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.2s/it 23.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.2it/s 0.9s\n",
            "                   all         33        116      0.626      0.579      0.628      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/100      9.04G     0.7312     0.3359   0.002443        131        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.649      0.551      0.622      0.429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/100      9.08G     0.7358     0.3044   0.002387        100        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.0it/s 1.0s\n",
            "                   all         33        116      0.615      0.536      0.617      0.439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/100      9.04G     0.6959     0.2942   0.002411        143        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.7it/s 0.7s\n",
            "                   all         33        116      0.664      0.537      0.617      0.419\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/100      9.04G     0.6649     0.2646   0.002062         92        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.594       0.58      0.596      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/100      8.99G      0.656     0.2861   0.002495         94        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.6it/s 1.2s\n",
            "                   all         33        116      0.648      0.529       0.61      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/100      9.05G      0.644     0.2617   0.002139        116        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.1it/s 0.9s\n",
            "                   all         33        116      0.877      0.499      0.605      0.413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/100      9.04G     0.6473     0.2726   0.002268        131        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.2it/s 0.9s\n",
            "                   all         33        116      0.899        0.5      0.593      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/100      9.07G     0.6436     0.2671   0.002034         92        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1it/s 17.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.0it/s 1.0s\n",
            "                   all         33        116      0.881        0.5      0.588      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/100      9.02G     0.6651     0.2838   0.001986        104        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.0it/s 1.0s\n",
            "                   all         33        116      0.846      0.476      0.583      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/100       9.1G     0.6186     0.2567   0.002189        131        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1it/s 16.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.8it/s 1.1s\n",
            "                   all         33        116      0.847      0.473      0.601      0.417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/100      9.09G     0.6593     0.2913   0.002264         83        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.4it/s 1.4s\n",
            "                   all         33        116      0.661      0.541      0.606      0.425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/100      9.06G     0.6367     0.2755   0.002088         92        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.673      0.513      0.623      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/100      9.02G     0.6516     0.2827   0.002158         73        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.2it/s 0.9s\n",
            "                   all         33        116      0.715      0.519      0.621      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/100      9.05G     0.6378     0.2642   0.002256         57        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.9it/s 1.1s\n",
            "                   all         33        116        0.8      0.547      0.644      0.437\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/100      9.04G     0.5529      0.216   0.002175        104        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.5s/it 27.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.781      0.548      0.642      0.437\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/100      9.08G     0.5714     0.2176   0.002028         47        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.2it/s 0.9s\n",
            "                   all         33        116      0.645      0.552      0.638      0.441\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/100      9.03G     0.5583     0.2112   0.002156         53        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.765      0.542      0.646      0.439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/100      9.04G     0.5747     0.2142      0.002         59        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.764      0.543      0.638      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     95/100      9.07G     0.5525     0.1986   0.001999         64        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s\n",
            "                   all         33        116      0.722      0.542      0.634      0.429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     96/100      9.04G     0.5206     0.1882   0.002058         55        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0it/s 18.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.2it/s 0.9s\n",
            "                   all         33        116      0.714      0.538      0.635      0.431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     97/100      8.98G     0.5137     0.1793   0.001894         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 20.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.715      0.546      0.644      0.431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     98/100      9.02G     0.5527     0.2234   0.002138         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.1s/it 21.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.2it/s 0.9s\n",
            "                   all         33        116      0.713      0.545      0.639      0.432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     99/100      9.05G     0.5265     0.1842   0.001906         54        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.9it/s 1.1s\n",
            "                   all         33        116      0.722      0.543      0.643      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    100/100      9.08G     0.5234     0.1963   0.001986         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19/19 1.0s/it 19.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s\n",
            "                   all         33        116      0.731      0.544      0.647      0.437\n",
            "\n",
            "100 epochs completed in 0.667 hours.\n",
            "Optimizer stripped from /content/runs/detect/train2/weights/last.pt, 44.0MB\n",
            "Optimizer stripped from /content/runs/detect/train2/weights/best.pt, 44.0MB\n",
            "\n",
            "Validating /content/runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.4.14 üöÄ Python-3.12.12 torch-2.9.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "YOLO26m summary (fused): 132 layers, 20,352,536 parameters, 0 gradients, 67.9 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.5it/s 0.6s\n",
            "                   all         33        116      0.751      0.591      0.627      0.449\n",
            "             bolt side          3          9      0.955      0.333      0.427      0.208\n",
            "              bolt nut         25         73      0.727      0.918      0.934      0.731\n",
            "             bolt head          7         22      0.725      0.864      0.869      0.708\n",
            "             blur bolt          5         12      0.598       0.25      0.278      0.151\n",
            "Speed: 0.2ms preprocess, 13.6ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train2\u001b[0m\n",
            "üí° Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "# Phase 1 ‚Äî freeze (200 epochs)\n",
        "!yolo detect train \\\n",
        "  data=/content/data.yaml \\\n",
        "  model=yolo26m.pt \\\n",
        "  epochs=200 \\\n",
        "  imgsz=640 \\\n",
        "  batch=16 \\\n",
        "  freeze=10 \\\n",
        "  project=/content/runs \\\n",
        "  name=y26m_phase1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "ckpt = \"/content/runs/detect/y26m_phase1/weights/last.pt\"\n",
        "print(\"Checkpoint Phase 1:\", ckpt, \"| existe:\", os.path.isfile(ckpt))"
      ],
      "metadata": {
        "id": "f4IuiqH6pRgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 2 ‚Äî unfreeze (400 epochs suppl√©mentaires)\n",
        "!yolo detect train \\\n",
        "  data=/content/data.yaml \\\n",
        "  model=/content/runs/detect/y26m_phase1/weights/last.pt \\\n",
        "  epochs=400 \\\n",
        "  imgsz=640 \\\n",
        "  batch=16 \\\n",
        "  project=/content/runs \\\n",
        "  name=y26m_phase2"
      ],
      "metadata": {
        "id": "Jb74cbiipVlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training algorithm will parse the images in the training and validation directories and then start training the model. At the end of each training epoch, the program runs the model on the validation dataset and reports the resulting mAP, precision, and recall. As training continues, the mAP should generally increase with each epoch. Training will end once it goes through the number of epochs specified by `epochs`.\n",
        "\n",
        "> **NOTE:** Make sure to allow training to run to completion, because an optimizer runs at the end of training that strips out unneeded layers from the model.\n",
        "\n",
        "The best trained model weights will be saved in `content/runs/detect/train/weights/best.pt`. Additional information about training is saved in the `content/runs/detect/train` folder, including a `results.png` file that shows how loss, precision, recall, and mAP progressed over each epoch."
      ],
      "metadata": {
        "id": "vv0EYWJ5V6mC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo8BJRXeg0Ap"
      },
      "source": [
        "#6.&nbsp;Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has been trained; now it's time to test it! The commands below run the model on the images in the validation folder and then display the results for the first 10 images. This is a good way to confirm your model is working as expected. Click Play on the blocks below to see how your model performs."
      ],
      "metadata": {
        "id": "BX3PTrEPacGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PooP5Vjsg2Jn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3330eb-1fbc-4d27-8bde-8d37087e903a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/cfg/__init__.py\", line 956, in entrypoint\n",
            "    model = YOLO(model, task=task)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/model.py\", line 76, in __init__\n",
            "    super().__init__(model=model, task=task, verbose=verbose)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\", line 144, in __init__\n",
            "    self._load(model, task=task)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\", line 283, in _load\n",
            "    self.model, self.ckpt = load_checkpoint(weights)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\", line 1507, in load_checkpoint\n",
            "    ckpt, weight = torch_safe_load(weight)  # load ckpt\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\", line 1455, in torch_safe_load\n",
            "    ckpt = torch_load(file, map_location=\"cpu\")\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/patches.py\", line 158, in torch_load\n",
            "    return torch.load(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1484, in load\n",
            "    with _open_file_like(f, \"rb\") as opened_file:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 759, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 740, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "                     ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/runs/detect/y26m_phase2/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "# √âvaluation sur test (d√©fini dans data.yaml)\n",
        "!yolo detect val \\\n",
        "  data=/content/data.yaml \\\n",
        "  model=/content/runs/detect/y26m_phase2/weights/best.pt \\\n",
        "  imgsz=640 \\\n",
        "  split=test\n",
        "\n",
        "# Pr√©diction et sauvegarde des images annot√©es de validation\n",
        "!yolo detect predict \\\n",
        "  model=/content/runs/detect/y26m_phase2/weights/best.pt \\\n",
        "  source=/content/data/val/images \\\n",
        "  imgsz=640 \\\n",
        "  conf=0.25 \\\n",
        "  save=True \\\n",
        "  project=/content/runs \\\n",
        "  name=pred_val_y26m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEEObQqoiGrs"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "for image_path in glob.glob(f'/content/runs/detect/predict/*.jpg')[:10]:\n",
        "  display(Image(filename=image_path, height=400))\n",
        "  print('\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model should draw a box around each object of interest in each image. If it isn't doing a good job of detecting objects, here are a few tips:\n",
        "\n",
        "1. Double-check your dataset to make sure there are no labeling errors or conflicting examples.\n",
        "2. Increase the number of epochs used for training.\n",
        "3. Use a larger model size (e.g. `yolo11l.pt`).\n",
        "4. Add more images to the training dataset. See my [dataset video](https://www.youtube.com/watch?v=v0ssiOY6cfg) for tips on how to capture good training images and improve accuracy.\n",
        "\n",
        "You can also run the model on video files or other images images by uploading them to this notebook and using the above `!yolo detect predict` command, where `source` points to the location of the video file, image, or folder of images. The results will be saved in `runs/detect/predict`.\n",
        "\n",
        "Drawing boxes on images is great, but it isn't very useful in itself. It's also not very helpful to just run this models inside a Colab notebook: it's easier if we can just run it on a local computer. Continue to the next section to see how to download your newly trained model and run it on a local device."
      ],
      "metadata": {
        "id": "EGiQw_gWbSBa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7yrFRViVczX"
      },
      "source": [
        "#7.&nbsp;Deploy Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that your custom model has been trained, it's ready to be downloaded and deployed in an application! YOLO models can run on a wide variety of hardware, including PCs, embedded systems, and phones. Ultralytics makes it easy to convert the YOLO models to various formats (`tflite`, `onnx`, etc.) and deploy them in a variety of environments.\n",
        "\n",
        "This section shows how to download the model and provides links to instructions for deploying it on your PC and edge devices like the Raspberry Pi."
      ],
      "metadata": {
        "id": "FEtybPmB_ERi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Download YOLO Model\n",
        "\n",
        "First, zip and download the trained model by running the code blocks below.\n",
        "\n",
        "The code creates a folder named `my_model`, moves the model weights into it, and renames them from `best.pt` to `my_model.pt`. It also adds the training results in case you want to reference them later. It then zips the folder as `my_model.zip`."
      ],
      "metadata": {
        "id": "IcoBAeHXa86W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create \"my_model\" folder to store model weights and train results\n",
        "!mkdir /content/my_model\n",
        "!cp /content/runs/detect/train/weights/best.pt /content/my_model/my_model.pt\n",
        "!cp -r /content/runs/detect/train /content/my_model\n",
        "\n",
        "# Zip into \"my_model.zip\"\n",
        "%cd my_model\n",
        "!zip /content/my_model.zip my_model.pt\n",
        "!zip -r /content/my_model.zip train\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "qcBdnOA9v85S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43ypwonynLVu"
      },
      "outputs": [],
      "source": [
        "# This takes forever for some reason, you can also just download the model from the sidebar\n",
        "from google.colab import files\n",
        "\n",
        "files.download('/content/my_model.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 Deploy YOLO Model on Local Devices\n",
        "\n",
        "Next, we'll take our downloaded model and run it on a local device. This section provides instructions showing how to deploy YOLO models on various devices.\n",
        "\n",
        "I wrote a basic Python script, `yolo_detect.py`, that shows how to load a model, run inference on an image source, parse the inference results, and display boxes around each detected class in the image. The [script](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/blob/main/yolo_detect.py) gives an example of how to work with Ultralytics YOLO models in Python, and it can be used as a starting point for more advanced applications."
      ],
      "metadata": {
        "id": "YL06c6pb_UqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.1 Deploy on PC (Windows, Linux, or macOS)\n",
        "\n",
        "The easiest way to run Ultralytics models on a PC is using Anaconda. Anaconda sets up a virtual Python environment and allows you to easily install Ultralytics and PyTorch. It automatically installs CUDA and cuDNN, which allows you to speed up model inference with your NVIDIA GPU.\n",
        "\n",
        "> **NOTE:** My YouTube video (link to be added) shows how to deploy your model on a PC. It walks through the following steps, so watch the video if you prefer having visual instructions.\n",
        "\n",
        "**1. Download and Install Anaconda**\n",
        "\n",
        "Go to the Anaconda download page at https://anaconda.com/download, click the ‚Äúskip registration‚Äù button, and then download the package for your OS. When it's finished downloading, run the installer and click through the installation steps. You can use the default options for installation.\n",
        "\n",
        "**2. Set up virtual environment**\n",
        "\n",
        "Once it's installed, run Anaconda Prompt from the Start Bar. (If you're on macOS or Linux, just open a command terminal).\n",
        "\n",
        "Issue the following commands to create a new Python environment and activate it:\n",
        "\n",
        "```\n",
        "conda create --name yolo-env1 python=3.12 -y\n",
        "conda activate yolo-env1\n",
        "```\n",
        "\n",
        "Install Ultralytics (which also installs import libraries like OpenCV-Python, Numpy, and PyTorch) by issuing the following command:\n",
        "\n",
        "```\n",
        "pip install ultralytics\n",
        "```\n",
        "\n",
        "If you have an NVIDIA GPU, you can install the GPU-enabled version of PyTorch by issuing the following command:\n",
        "\n",
        "```\n",
        "pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "```\n",
        "\n",
        "**3. Extract downloaded model**\n",
        "Take the `my_model.zip` file you downloaded in Step 7.1 and unzip it to a folder on your PC. In the Anaconda Prompt terminal, move into the unzipped folder using:\n",
        "\n",
        "```\n",
        "cd path/to/folder\n",
        "```\n",
        "\n",
        "**4. Download and run yolo_detect.py**\n",
        "\n",
        "Download the `yolo_detect.py` script into the `my_model` folder using:\n",
        "\n",
        "```\n",
        "curl -o yolo_detect.py https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/yolo_detect.py\n",
        "```\n",
        "\n",
        "Alright! We're ready to run the script. To run inference with a yolov8s model on a USB camera at 1280x720 resolution, issue:\n",
        "\n",
        "```\n",
        "python yolo_detect.py --model my_model.pt --source usb0 --resolution 1280x720\n",
        "```\n",
        "\n",
        "A window will appear showing a live feed from your webcam with boxes drawn around detected objects in each frame.\n",
        "\n",
        "You can also run the model on an video file, image, or folder of images. To see a full list of arguments for `yolo_detect.py`, issue `python yolo_detect.py --help` or see the [README file](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/blob/main/README.md).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gzaJQ2sGEPhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.2 Deploy on Raspberry Pi\n",
        "\n",
        "Keep an eye out for an article showing how to convert YOLO models to NCNN format and run them on the Raspberry Pi!"
      ],
      "metadata": {
        "id": "GelkpRLPEYmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.&nbsp;Conclusion"
      ],
      "metadata": {
        "id": "y8fOJ4g8Q5x0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! You've successfully trained and deployed a YOLO object detection model. üòÄ\n",
        "\n",
        "Next, you can extend your application beyond just drawing boxes and counting objects. Add functionality like logging the number of objects detected over time or taking a picture when certain objects are detected. Check out some example applications at our GitHub repository: https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models\n",
        "\n",
        "Thanks for working through this notebook, and good luck with your projects!"
      ],
      "metadata": {
        "id": "DEZGuG1-Peg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix: Common Errors"
      ],
      "metadata": {
        "id": "fXeDs6SaQBRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you run into any errors working through this notebook, please do the following:\n",
        "\n",
        "\n",
        "- Double-check that the dataset files are set up in the correct folder structure\n",
        "- Make sure there are no typos or errors in your labelmap file\n",
        "- Google search the error to look for solutions\n",
        "\n",
        "If none of those help, please submit an [Issue](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/issues) on the GitHub page. In this section, I will add resolutions to common errors as they come up."
      ],
      "metadata": {
        "id": "Q19ENCHRQOCH"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}